{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d40de6d-ce39-4f14-ba5a-eec6de4c3cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Embedding,GlobalAveragePooling1D\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "978d3248-9180-4318-a23f-7c31282e077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=10000\n",
    "max_len=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4acded5-4552-454b-8eff-d7a7f18e77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test)=imdb.load_data(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af0659ec-de88-4501-b50b-1ae9e3ec4ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train,maxlen=max_len)\n",
    "X_test = pad_sequences(X_test,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "955be94d-d026-4b5f-b872-e8e3104b9ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=128,input_length=max_len),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4352ac0-32a1-4cc8-96f8-b3987c4b9313",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2921aeb2-ead8-4175-a3c3-c5908ee813d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6610 - loss: 0.6044 - val_accuracy: 0.8656 - val_loss: 0.3271\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8821 - loss: 0.2862 - val_accuracy: 0.8476 - val_loss: 0.3467\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9167 - loss: 0.2149 - val_accuracy: 0.8758 - val_loss: 0.2949\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9309 - loss: 0.1765 - val_accuracy: 0.8792 - val_loss: 0.3037\n",
      "Epoch 5/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9473 - loss: 0.1480 - val_accuracy: 0.8794 - val_loss: 0.3227\n",
      "Epoch 6/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9533 - loss: 0.1296 - val_accuracy: 0.8544 - val_loss: 0.3745\n",
      "Epoch 7/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9613 - loss: 0.1159 - val_accuracy: 0.8744 - val_loss: 0.3827\n",
      "Epoch 8/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9734 - loss: 0.0865 - val_accuracy: 0.8724 - val_loss: 0.4003\n",
      "Epoch 9/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9706 - loss: 0.0869 - val_accuracy: 0.8724 - val_loss: 0.4388\n",
      "Epoch 10/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9811 - loss: 0.0659 - val_accuracy: 0.8746 - val_loss: 0.4713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15ed2fd10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=10,batch_size=64,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ad2573b-00c1-41f3-bd27-eac172e5a0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step - accuracy: 0.4912 - loss: 0.6932\n",
      "Test Accuracy:48.41%\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy=model.evaluate(X_test,y_test)\n",
    "print(f\"Test Accuracy:{test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5c114c0-a7fb-4475-9ea5-b38964c4d788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review: I absolutely loved this movie, it was fantastic!\n",
      "Sentiment Score: 0.499\n",
      "Predicted Sentiment: Neutral ğŸ˜\n",
      "\n",
      "Review: This was the worst film I have ever seen.\n",
      "Sentiment Score: 0.499\n",
      "Predicted Sentiment: Neutral ğŸ˜\n",
      "\n",
      "Review: The movie was okay, not great but not bad either.\n",
      "Sentiment Score: 0.499\n",
      "Predicted Sentiment: Neutral ğŸ˜\n",
      "\n",
      "Review: Worst movie Iâ€™ve ever seen. Total waste of time.\n",
      "Sentiment Score: 0.499\n",
      "Predicted Sentiment: Neutral ğŸ˜\n",
      "\n",
      "Review: Terrible acting and a confusing plot. I couldnâ€™t finish it.\n",
      "Sentiment Score: 0.499\n",
      "Predicted Sentiment: Neutral ğŸ˜\n"
     ]
    }
   ],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "word_index = {k: (v + 3) for k, v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "\n",
    "def predict_review(text):\n",
    "    words = text.lower().split()\n",
    "    encoded = [1]  # Start token\n",
    "    for word in words:\n",
    "        idx = word_index.get(word, 2)  # Unknown = 2\n",
    "        if idx < vocab_size:  # Only keep if in allowed vocab range\n",
    "            encoded.append(idx)\n",
    "        else:\n",
    "            encoded.append(2)  # Treat as unknown\n",
    "            \n",
    "    padded = pad_sequences([encoded], maxlen=max_len, padding='post', truncating='post')\n",
    "    prediction = model.predict(padded, verbose=0)[0][0]\n",
    "    \n",
    "    print(f\"\\nReview: {text}\")\n",
    "    print(f\"Sentiment Score: {prediction:.3f}\")\n",
    "    if prediction >= 0.7:\n",
    "        print(\"Predicted Sentiment: Positive ğŸ˜Š\")\n",
    "    elif prediction <= 0.3:\n",
    "        print(\"Predicted Sentiment: Negative ğŸ˜\")\n",
    "    else:\n",
    "        print(\"Predicted Sentiment: Neutral ğŸ˜\")\n",
    "\n",
    "\n",
    "# 5. Just type your review here ğŸ‘‡\n",
    "predict_review(\"I absolutely loved this movie, it was fantastic!\")\n",
    "predict_review(\"This was the worst film I have ever seen.\")\n",
    "predict_review(\"The movie was okay, not great but not bad either.\")\n",
    "predict_review(\"Worst movie Iâ€™ve ever seen. Total waste of time.\")\n",
    "predict_review(\"Terrible acting and a confusing plot. I couldnâ€™t finish it.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783bc6a3-f4fd-4adc-b115-6817277466f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
